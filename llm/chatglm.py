import re  # 导入正则表达式模块
import json  # 导入JSON模块，用于处理JSON数据
import logging  # 导入日志模块，用于记录日志信息
from typing import (  # 导入类型注释模块，用于指定变量类型
    Any,
    Dict,
    List,
    Optional,
)

import requests  # 导入requests模块，用于执行HTTP请求
# from termcolor import colored  # 导入termcolor模块，用于在控制台中输出彩色文本

import urllib3  # 导入urllib3模块，用于底层HTTP连接

# from config import GLM_NEW_API_URL, GLM_Authorization  # 从config.py中导入GLM_NEW_API_KEY
from llm.config import GLM_NEW_API_URL, GLM_Authorization  # 从config.py中导入GLM_NEW_API_KEY

urllib3.disable_warnings()  # 禁用urllib3的警告信息

logger = logging.getLogger(__name__)  # 配置日志记录器，获取当前模块的日志记录器

class _ChatGLMEndpointClient:  # 定义一个内部API客户端类
    """An API client that talks to a ChatGLM llm endpoint. 与 ChatGLM llm 端点对话的 API 客户端"""

    api_url: str = GLM_NEW_API_URL  # 定义API的URL
    headers: Dict = {  # 定义请求头部
        'Host': 'api.glm.ai',
        'Authorization': GLM_Authorization
    }
    
    def post(self, request: Any) -> Any:  # 定义发送POST请求的方法
        retries = 3  # 设置重试次数
        for _ in range(retries):  # 循环尝试发送请求
            response = requests.post(self.api_url, data=json.dumps(request), headers=self.headers, verify=False)  # 发送请求并禁用SSL验证
            response.encoding = 'UTF-8'  # 设置响应的编码为UTF-8
            try:
                choice = response.json()['choices'][0]  # 解析响应内容
                if choice['finish_reason'] != 'stop':  # 检查结束原因是否为'stop'
                    print(f"Finish reason: {choice['finish_reason']}")  # 打印结束原因
                    raise NotImplementedError  # 如果不是，抛出未实现错误
                return response.json()  # 返回JSON格式的响应数据
            except requests.exceptions.JSONDecodeError:  # 捕获JSON解析错误
                print(f"Response content: {response.text}")  # 打印响应文本
        raise NotImplementedError  # 如果重试失败，抛出未实现错误

class ChatGLM:  # 定义ChatGLM类
    """Wrapper around ChatGLM large language models.
    To use, you should have the environment variable
    ``ChatGLM_API_KEY`` and ``ChatGLM_GROUP_ID`` set with your API key,
    or pass them as a named parameter to the constructor.
    围绕 ChatGLM 大型语言模型的 rapper。
    使用时，您需要在环境变量ChatGLM_API_KEY`` 和 `ChatGLM_GROUP_ID`` 设置为您的 API 密钥、或将它们作为命名参数传递给构造函数。
    Example:
     .. code-block:: python
         from langchain.llms.ChatGLM import ChatGLM
         ChatGLM = ChatGLM(model="<model_name>", ChatGLM_api_key="my-api-key",
          ChatGLM_group_id="my-group-id")
    示例：
     代码块:: python
         from langchain.llms.ChatGLM import ChatGLM
         ChatGLM = ChatGLM(model="<model_name>", ChatGLM_api_key="my-api-key"、
          ChatGLM_group_id="my-group-id")
    """
    # 类和方法的注释已经给出

    @property
    def _default_params(self) -> Dict[str, Any]:  # 定义默认参数的属性
        return {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "stream": False,
        }

    @property
    def _llm_type(self) -> str:  # 定义语言模型类型的属性
        """Return type of llm."""
        return "ChatGLM"

    def __init__(self, **data: Any):  # 初始化方法
        super().__init__(**data)  # 调用基类的初始化方法
        self.model: str = "glm-4-public"  # 设置模型名称
        # self.model: str = "chatglm3-32b-v0.6-added"
        # self.model: str = "chatglm3-32b-v0.8-dpo-240102"
        # self.model: str = "chatglm3-32b-v0.9"
        self.max_tokens: int = 2048  # 设置最大令牌数
        self.client: _ChatGLMEndpointClient = _ChatGLMEndpointClient()  # 创建API客户端实例
    
    def generate(self, prompt: str):  # 定义生成方法
        r"""Call out to ChatGLM's completion endpoint to chat
        Args:
            prompt: The prompt to pass into the model.
        Returns:
            The string generated by the model.
        Example:
            .. code-block:: python
                response = ChatGLM("Tell me a joke.")
        调用 ChatGLM 的完成端点进行聊天
        参数
            prompt： 要传入模型的提示。
        返回
            模型生成的字符串。
        示例： ：
            代码块:: python
                response = ChatGLM("Tell me a joke.")
        """
        request = self._default_params  # 获取默认参数
        
        # print(colored("Prompt: " + json.dumps([prompt]), 'red'))
        request["messages"] = [{
            "role": "user",
            "content": prompt
        }]  # 构造请求消息
        response = self.client.post(request)  # 发送请求
        response = response['choices'][0]['message']['content'].rstrip()  # 解析响应内容并去除尾部空白
        return response  # 返回响应内容

    def invoke(
        self,
        messages,
        **kwargs: Any,
    ) -> str:  # 定义invoke方法
        request = kwargs  # 获取关键字参数
        request["messages"] = messages  # 添加消息到请求
        request.update(self._default_params)  # 更新请求参数
        response = self.client.post(request)  # 发送请求
        return response['choices'][0]['message']['content'].rstrip()  # 解析并返回响应内容
    

if __name__ == "__main__":  # 如果直接运行此文件
    ChatGLM = ChatGLM()  # 创建ChatGLM实例
    response = ChatGLM.generate("你好！请问你是？")  # 调用生成方法
    print(response)  # 打印响应结果
